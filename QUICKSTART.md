# Deep Sight - Quick Start Guide

## ğŸš€ Getting Started in 5 Minutes

### Step 1: Install Dependencies

```powershell
# Install Python packages
pip install -r requirements.txt
```

### Step 2: Install and Setup Ollama

```powershell
# Download from https://ollama.ai/
# After installation, pull the llava model
ollama pull llava

# Verify Ollama is running
ollama list
```

### Step 3: Run the Application

**Option A: Run Everything (Recommended)**
```powershell
python main.py both
```

This will start:
- FastAPI server on http://localhost:8000
- Streamlit UI on http://localhost:8501

**Option B: Run Separately**
```powershell
# Terminal 1: Start API
python main.py api

# Terminal 2: Start UI
python main.py ui
```

### Step 4: Access the Application

1. **Web UI**: Open http://localhost:8501 in your browser
2. **API Docs**: Open http://localhost:8000/docs for Swagger documentation

## ğŸ“– Usage Examples

### Process a Single Image (Web UI)

1. Go to "Process Image" page
2. Upload an image or provide a URL
3. Click "Process Image"
4. View results: extracted text, translations, and description

### Batch Process a Folder (Web UI)

1. Go to "Batch Processing" page
2. Enter the absolute folder path (e.g., `D:\images`)
3. Click "Start Batch Processing"
4. Go to "Batch Status" page to monitor progress

### Using the API

**Process Image from URL**
```powershell
curl -X POST "http://localhost:8000/api/process/url" `
  -H "Content-Type: application/json" `
  -d '{
    "image_url": "https://example.com/image.jpg",
    "save_to_storage": true
  }'
```

**Start Batch Processing**
```powershell
curl -X POST "http://localhost:8000/api/batch/process" `
  -H "Content-Type: application/json" `
  -d '{
    "folder_path": "D:/images",
    "recursive": false
  }'
```

## âš™ï¸ Configuration

Edit `config/config.yml` to customize:

```yaml
# Change Ollama model
ollama:
  model: llava  # or llava:13b, llava:34b

# Change ports
app:
  ui_port: 8501
  api_port: 8000

# Adjust image size
image:
  max_width: 1024
  max_height: 1024
```

## ğŸ”§ Troubleshooting

### Issue: "Connection refused" to Ollama

**Solution:** Make sure Ollama is running
```powershell
ollama serve
```

### Issue: OCR models downloading slowly

**Solution:** This is normal on first run. Keras-OCR downloads ~200MB of models. Wait patiently.

### Issue: Port already in use

**Solution:** Change ports in `config/config.yml`
```yaml
app:
  ui_port: 8502  # Change to any available port
  api_port: 8001
```

### Issue: Memory errors with TensorFlow

**Solution:** Use smaller batch sizes or switch to Tesseract OCR
```yaml
tensorflow:
  model_type: tesseract  # Lighter on memory
```

## ğŸ“ Directory Structure After First Run

```
deep-sight/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/          # Processed images saved here
â”‚   â””â”€â”€ temp/            # Temporary files
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ deep_sight.log   # Application logs
â””â”€â”€ tensor/
    â””â”€â”€ ocr_model/       # Downloaded OCR models
```

## ğŸ¯ Common Workflows

### Workflow 1: Process Images from Web
1. Upload images via UI
2. View results immediately
3. Download or save to storage

### Workflow 2: Batch Process Local Folder
1. Start batch via UI or API
2. Monitor progress in real-time
3. Resume if interrupted (automatic)
4. Browse and edit results

### Workflow 3: API Integration
1. Use REST API in your application
2. Post images programmatically
3. Retrieve structured JSON results
4. Build custom workflows

## ğŸ“Š Understanding Results

Each processed image generates:
```yaml
image_name: photo.jpg
extracted_text: "Text found in image..."
translated_text_hindi: "à¤›à¤µà¤¿ à¤®à¥‡à¤‚ à¤®à¤¿à¤²à¤¾ à¤ªà¤¾à¤ ..."
translated_text_english: "Text found in image..."
description: "A detailed description of the image..."
metadata:
  model_name: llava
  datetime: "2025-11-02T16:00:00"
  processing_time: 12.5
  image_size:
    width: 1024
    height: 768
```

## ğŸš€ Next Steps

- Explore the Streamlit UI features
- Try the REST API via Swagger docs
- Customize configuration for your needs
- Process your own image collections
- Integrate with your applications

## ğŸ’¡ Tips

1. **Performance**: First image takes longer (model loading). Subsequent images are faster.
2. **Batch Processing**: Progress is saved every 5 images. Safe to interrupt and resume.
3. **LLM Quality**: Use larger models (llava:13b, llava:34b) for better descriptions.
4. **Storage**: Processed images are copied to `data/images/` folder.

## ğŸ†˜ Need Help?

- Check the full README.md for detailed documentation
- Review logs in `logs/deep_sight.log`
- Open an issue on GitHub
- Check Ollama documentation at https://ollama.ai/

Happy processing! ğŸ‰
